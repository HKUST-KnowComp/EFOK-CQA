"""
A base class for existential first order formulas
It supports the verification and query answering tasks given the formula
For the verification, there is no free_vars
For the query answering, there should be at least one free_vars
Several assumptions about the formula
- In DNF
- Only with existential quantifier
The query is generated by the following steps:

>>>> Construct the conjunctive query skeleton:
    1. Define the number of terms, including
        - p existential vars
        - q free vars
        - r literals
        There are p + q + r terms
    2. Construct the edges between terms by random sampling, and then construct
        a connective graph, the edge is constructed by the certain ratio $P_e$
    3. Randomly corrupt the edges with negation $P_n$
<<<< In this way, the conjunctive query skeleton is constructed

>>>> Construct the DNF formula
    The key of DNF construction is that there must be at least one variable be
    shared in two conjunctive query
    1. determin the variables to be shared (more than one)
    2. determin the objects to be shared (not necessary more than one)
<<<<

>>>> Sampling accross the graph
    1. For question answering task
        1. sample the full graph,
            so that the predicates and objects are determined
        2. search over partial graph and full graph,
            and find out the answer tuples
    2. Instantiation of the query graph
<<<<
"""
import copy
import random
from abc import ABC, abstractmethod
from collections import defaultdict, OrderedDict
import json
from typing import Dict, List, Union
from random import sample
from constraint import *
from copy import deepcopy

import numpy as np
import torch

from src.language.tnorm import Tnorm
from src.structure.neural_binary_predicate import NeuralBinaryPredicate
from src.structure.knowledge_graph import KnowledgeGraph, csp_efo1, ground_variable, kg2matrix, \
    labeling_triples, label_triples_with_assign, ground_predicate, csp_efox, candidate_set_to_ans
from src.structure.knowledge_graph_index import KGIndex
from FIT import solve_EFO1, solve_conjunctive


# from src.utils.data import RaggexxdBatch


def check_ldict(ldict):
    """
    Ldict is a nested dict that stores the GROUNDED information
    """
    assert 'op' in ldict
    op = ldict['op']
    assert 'args' in ldict
    args = ldict['args']

    if op == Term.op:
        assert 'name' in args
        assert 'state' in args
        assert 'entity_id_list' in args
    if op == Atomic.op:
        assert 'name' in args
        assert 'relation_id_list' in args
        check_ldict(args['term1'])
        check_ldict(args['term2'])
    if op == Negation.op:
        assert 'formula' in args
        check_ldict(args['formula'])
    if op == Conjunction.op or op == Disjunction.op:
        assert 'formulas' in args
        for f in args['formulas']:
            check_ldict(f)


def get_ldict(op, **args):
    ans = {'op': op, 'args': args}
    check_ldict(ans)
    return ans


class Lobject:
    op = "default"

    @abstractmethod
    def to_ldict(self) -> Dict:
        pass

    @abstractmethod
    def lstr(self) -> str:
        pass

    def __repr__(self):
        check_ldict(self.to_ldict())
        return json.dumps(self.to_ldict(), indent=1)

    @abstractmethod
    def get_atomics(self) -> Dict[str, 'Atomic']:
        pass


class Term(Lobject):
    EXISTENTIAL = 1
    FREE = 2
    UNIVERSAL = 3
    SYMBOL = 4
    # GROUNDED = 5

    op = "term"

    def __init__(self, state, name):
        self.state = state
        self.name = name
        self.parent_predicate = None
        self.entity_id_list = []

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']
        name = args['name']
        state = args['state']
        object = cls(name=name, state=state)
        object.entity_id_list = args['entity_id_list']
        return object

    def to_ldict(self):
        ldict = {'op': self.op,
                 'args': {
                     'state': self.state,
                     'name': self.name,
                     'entity_id_list': self.entity_id_list}}
        return ldict

    def lstr(self) -> str:
        return self.name

    @property
    def is_free(self):
        return self.state == self.FREE

    @property
    def is_existential(self):
        return self.state == self.EXISTENTIAL

    @property
    def is_universal(self):
        return self.state == self.UNIVERSAL

    @property
    def is_symbol(self):
        return self.state == self.SYMBOL

    @property
    def is_grounded(self):
        return self.is_symbol or (self.state == Term.GROUNDED)


class Formula(Lobject):
    def __init__(self) -> None:
        super().__init__()

    @staticmethod
    def parse(ldict):
        op = ldict['op']
        if op == Atomic.op:
            return Atomic.parse(ldict)
        elif op == Negation.op:
            return Negation.parse(ldict)
        elif op == Conjunction.op:
            return Conjunction.parse(ldict)
        elif op == Disjunction.op:
            return Disjunction.parse(ldict)
        else:
            raise NotImplementedError("Unsupported Operator")

    @abstractmethod
    def get_atomics(self) -> Dict[str, 'Atomic']:
        pass

    @property
    def num_predicates(self):
        pass


class Atomic(Formula):
    op = 'pred'

    def __init__(self,
                 name: str,
                 head: Term,
                 tail: Term) -> None:
        self.name = name
        self.relation = name
        self.head = head
        self.tail = tail
        self.relation_id_list = []
        self.negated = False

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']

        name = args['name']
        head = Term.parse(args['head'])
        tail = Term.parse(args['tail'])
        object = cls(name=name, head=head, tail=tail)
        object.relation_id_list = args['relation_id_list']
        head.parent_predicate = object
        tail.parent_predicate = object
        return object

    def to_ldict(self):
        obj = {
            'op': self.op,
            'args': {
                'name': self.name,
                'relation_id_list': self.relation_id_list,
                'head': self.head.to_ldict(),
                'tail': self.tail.to_ldict()
            }
        }
        return obj

    def lstr(self):
        lstr = f"{self.name}({self.head.name},{self.tail.name})"
        return lstr

    def get_atomics(self) -> Dict[str, 'Atomic']:
        ans = {self.name: self}
        return ans

    def get_terms(self):
        return [self.head, self.tail]

    @property
    def num_predicates(self):
        return 1


class Connective(Formula):
    pass


class Negation(Connective):
    op = 'neg'

    def __init__(self, formula: Formula) -> None:
        self.formula = formula

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']
        formula = Formula.parse(args['formula'])
        if formula.op == 'pred':
            formula.negated = True
        return cls(formula)

    def to_ldict(self):
        obj = {
            'op': self.op,
            'args': {'formula': self.formula.to_ldict()}
        }
        return obj

    def lstr(self) -> str:
        lstr = f"!({self.formula.lstr()})"
        return lstr

    def get_atomics(self) -> Dict[str, 'Atomic']:
        ans = {}
        ans.update(self.formula.get_atomics())
        return ans

    @property
    def num_predicates(self):
        return self.formula.num_predicates


class Conjunction(Connective):  # TODO: Don't those formulas require a sorting of its sub formulas?
    op = 'conj'

    def __init__(self, formulas: List[Formula]) -> None:
        self.formulas = formulas

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']
        formula_dict_list = args['formulas']
        formulas = [Formula.parse(formula_dict)
                    for formula_dict in formula_dict_list]
        return cls(formulas)

    def to_ldict(self):
        obj = {
            'op': self.op,
            'args': {'formulas': [f.to_ldict() for f in self.formulas]}
        }
        return obj

    def lstr(self):
        lstr = "&".join(f"({f.lstr()})" for f in self.formulas)
        return lstr

    def get_atomics(self) -> Dict[str, 'Atomic']:
        ans = {}
        for f in self.formulas:
            ans.update(f.get_atomics())
        return ans

    @property
    def num_predicates(self):
        return sum([formula.num_predicates for formula in self.formulas])


class Disjunction(Connective):
    op = 'disj'

    def __init__(self, formulas: List[Formula]) -> None:
        self.formulas = formulas

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']
        formula_dict_list = args['formulas']
        formulas = [Formula.parse(formula_dict)
                    for formula_dict in formula_dict_list]
        return cls(formulas)

    def to_ldict(self):
        obj = {
            'op': self.op,
            'args': {'formulas': [f.to_ldict() for f in self.formulas]}
        }
        return obj

    def lstr(self):
        lstr = "|".join(f"({f.lstr()})" for f in self.formulas)
        return lstr

    def get_atomics(self) -> Dict[str, 'Atomic']:
        ans = {}
        for f in self.formulas:
            ans.update(f.get_atomics())
        return ans

    @property
    def num_predicates(self):
        return sum([formula.num_predicates for formula in self.formulas])


class ConjunctiveFormula:
    """
    The first order formula is supposed to be without disjunction, since we always utilize the DNF normal form.
    it also includes information about the quantifiers

    self.formula is parsed from the formula and provide the operator tree for
        evaluation
    self.predicate_dict stores each predicates by its name, which are edges
    self.symbol_dict stores each symbol by its name
    self.variable_dict stores each variable by its name

    self.easy_answer_list list for easy answers
    self.hard_answer_list list for hard answers
    self.noisy_answer_list list for noisy answers

    each answer is a dict whose keys are the variable and values are the list of possible answers
    """

    def __init__(self,
                 formula: Formula) -> None:
        self.formula: Formula = formula
        self.easy_answer_list = []
        self.hard_answer_list = []
        self.noisy_answer_list = []
        self.grounding_dict_list = []

        # update internal storage
        self.predicate_dict: Dict[str, Atomic] = {}
        self.pred_grounded_relation_id_dict: Dict[str, List] = {}

        self.term_dict: Dict[str, Term] = {}
        self.term_grounded_entity_id_dict: Dict[str, List] = {}

        self.term_name2predicate_name_dict: Dict[str, str] = defaultdict(list)
        # run initialization
        self._init_query()

    def _init_query(self):
        self.predicate_dict = self.formula.get_atomics()
        self.pred_grounded_relation_id_dict = {
            name: predicate.relation_id_list
            for name, predicate in self.predicate_dict.items()
        }

        self.term_dict = OrderedDict()
        for _, pred in self.predicate_dict.items():
            for t in pred.get_terms():
                self.term_dict[t.name] = t

        # self.term_local_embedding_dict = {name: None
        #   for name in self.term_dict}
        self.term_grounded_entity_id_dict = {name: term.entity_id_list
                                             for name, term in self.term_dict.items()}

        for pred_name, predicate in self.predicate_dict.items():
            head, tail = predicate.get_terms()
            self.term_name2predicate_name_dict[head.name].append(pred_name)
            self.term_name2predicate_name_dict[tail.name].append(pred_name)

    def append_relation_and_symbols(self, append_dict):
        for k, v in append_dict.items():
            if k in self.term_dict:
                self.term_grounded_entity_id_dict[k].append(v)
            else:
                self.pred_grounded_relation_id_dict[k].append(v)

    def pop_relation_and_symbols(self, index, pop_dict):
        for pop_key in pop_dict:
            if pop_key in self.term_dict:
                self.term_grounded_entity_id_dict[pop_key].pop(index)
            else:
                self.pred_grounded_relation_id_dict[pop_key].pop(index)

    def append_qa_instances(self,
                            append_dict,
                            easy_answers=[],
                            hard_answers=[],
                            noisy_answer=[]):
        self.append_relation_and_symbols(append_dict)
        self.easy_answer_list.append(easy_answers)
        self.hard_answer_list.append(hard_answers)
        self.noisy_answer_list.append(noisy_answer)

    def has_term_grounded_entity_id_list(self, key):
        return len(self.term_grounded_entity_id_dict[key]) > 0

    def get_term_grounded_entity_id_list(self, key):
        return self.term_grounded_entity_id_dict[key]

    def has_pred_grounded_relation_id_list(self, key):
        return len(self.pred_grounded_relation_id_dict[key]) > 0

    def get_pred_grounded_relation_id_list(self, key):
        return self.pred_grounded_relation_id_dict[key]

    def sample_query(self, data_kg: KnowledgeGraph, strict_meaningful_negation: bool, original_kg_matrix=None,
                     max_answer_size: int = None):
        """
        Same relation should not exist multiple times! Which means that multiple 'r1' is not allowed.
        Very important so that we can ground entity then predicate, separately.

        We return two things, 1.the grounding dict, 2. the list of answer tuple
        """
        grounded_dict = {}
        sub_graph_edge, sub_graph_negation_edge, pos_graph_nodes, pos_graph_edge = [], [], set(), set()
        free_variable_list = list(self.free_variable_dict.keys())
        for pred in self.predicate_dict.values():
            pred_triples = (pred.head.name, pred.name, pred.tail.name)
            if pred.negated:
                sub_graph_negation_edge.append(pred_triples)
            else:
                sub_graph_edge.append(pred_triples)
                pos_graph_nodes.add(pred.head.name)
                pos_graph_nodes.add(pred.tail.name)
                pos_graph_edge.add((pred.head.name, pred.tail.name))
        sub_kg_index = KGIndex()
        sub_kg_index.map_entity_name_to_id = {term: 0 for term in self.term_dict}
        sub_kg_index.map_relation_name_to_id = {predicate: 0 for predicate in self.predicate_dict}
        connected_sub_graph_edge = deepcopy(sub_graph_edge)  # Connect kg ensures meaningful negation.
        for negative_triples in sub_graph_negation_edge:
            neg_head, neg_rel, neg_tail = negative_triples  # Find edge that is not seen but both nodes have.
            if neg_head in pos_graph_nodes and neg_tail in pos_graph_nodes and \
                    (neg_head, neg_tail) not in pos_graph_edge and (neg_tail, neg_head) not in pos_graph_edge:
                connected_sub_graph_edge.append(negative_triples)
        labeled_connected_triples, node2index, index2node = labeling_triples(connected_sub_graph_edge)
        labeled_sub_graph_edge, _, _ = labeling_triples(sub_graph_edge)
        connected_kg = KnowledgeGraph(labeled_connected_triples, sub_kg_index)
        sub_kg = KnowledgeGraph(labeled_sub_graph_edge, sub_kg_index)
        connect_kg_matrix = kg2matrix(connected_kg)
        if original_kg_matrix is None:
            original_kg_matrix = kg2matrix(data_kg)
        node_be_anchor = [True if 's' in index2node[index] else False for index in index2node]
        proper_answer_got = False
        while not proper_answer_got:
            grounded_entity_list, exist_grounding = ground_variable(connect_kg_matrix, original_kg_matrix)
            while not exist_grounding:
                grounded_entity_list, exist_grounding = ground_variable(connect_kg_matrix, original_kg_matrix)
            grounded_relation_dict = ground_predicate(grounded_entity_list, sub_kg, data_kg)
            grounded_entity_dict = {index2node[index]: int(grounded_entity_list[index])
                                    for index in range(len(grounded_entity_list)) if node_be_anchor[index]}
            grounded_dict.update(grounded_relation_dict)
            grounded_dict.update(grounded_entity_dict)
            self.append_relation_and_symbols(grounded_dict)
            now_index = max([len(grounded) for grounded in self.term_grounded_entity_id_dict.values()]) - 1
            negation_pred_list = [negation_edge[1] for negation_edge in sub_graph_negation_edge]
            full_answer = self.deterministic_query_set(now_index, data_kg, negation_pred_list, True)
            if full_answer and (max_answer_size is None
                                or max([len(full_answer[free]) for free in free_variable_list]) <= max_answer_size):
                proper_answer_got = True
            else:
                self.pop_relation_and_symbols(now_index, grounded_dict)
                continue
            if len(free_variable_list) == 1:
                free_variable = free_variable_list[0]
                epfo_answer_tuple = set()
                for ans in full_answer[free_variable]:
                    epfo_answer_tuple.add((ans,))
            else:
                epfo_answer_tuple = self.deterministic_query_set_with_initialization(
                    now_index, data_kg, negation_pred_list, False, full_answer)
            self.pop_relation_and_symbols(now_index, grounded_dict)
        final_answer_tuple = deepcopy(epfo_answer_tuple)
        answer_has_changed = False
        if sub_graph_negation_edge:  # Actually, we only consider the case of only one negation edge.
            neg_edges = [[head, rel, tail, int(head not in node2index) + int(tail not in node2index)]
                         for head, rel, tail in sub_graph_negation_edge]
            grounded_neg_pred = {rel: False for head, rel, tail in sub_graph_negation_edge}
            # The answer list of free variables, however, not true answer, but the candidate list of each variable.
            # sorted(neg_edges, key=lambda x: x[3])
            now_head, now_predicate, now_tail, not_in_node_num = neg_edges.pop(0)
            if not_in_node_num == 0:  # Both head and tail has already been grounded, find an edge for restriction.
                head_entity, tail_entity = grounded_entity_list[node2index[now_head]], \
                    grounded_entity_list[node2index[now_tail]]
                neg_try_rel_set = data_kg.ht2r[(head_entity, tail_entity)]
                head_candidate, tail_candidate = full_answer[now_head], full_answer[now_tail]
                head_constraint = set.union(*[set(data_kg.node2or[head].keys()) for head in head_candidate])
                tail_constraint = set.union(*[set(data_kg.node2ir[tail].keys()) for tail in tail_candidate])
                neg_candidate_set = head_constraint.intersection(tail_constraint)
                other_to_try = neg_candidate_set.difference(neg_try_rel_set)
                neg_candidate_list = list(neg_try_rel_set) + list(other_to_try)
                not_meaningful_candidate = []
                for i in range(min(len(neg_candidate_list), len(neg_try_rel_set) + 10)):
                    guess_predicate = neg_candidate_list[i]
                    grounded_dict[now_predicate] = guess_predicate
                    self.append_relation_and_symbols(grounded_dict)
                    final_answer_tuple = self.deterministic_query_set_with_initialization(
                        now_index, data_kg, [neg_edge[1] for neg_edge in neg_edges], False, full_answer)
                    self.pop_relation_and_symbols(now_index, grounded_dict)
                    if final_answer_tuple and final_answer_tuple != epfo_answer_tuple:
                        grounded_neg_pred[now_predicate] = True
                        break
                    elif final_answer_tuple:
                        not_meaningful_candidate.append(guess_predicate)
                else:
                    if not_meaningful_candidate:
                        guess_predicate = random.choice(not_meaningful_candidate)
                        final_answer_tuple = epfo_answer_tuple
                    else:
                        guess_predicate = random.sample(set(range(0, data_kg.num_relations)) - neg_candidate_set, 1)[0]
                        #  answer_has_changed = True
                        #  when guess predicate is not in the candidate set, it does not change final ans
                    grounded_dict[now_predicate] = guess_predicate
            elif not_in_node_num == 1:  # Need to ground an edge along with new node.
                answer_has_changed = True
                if now_head in node2index:  # Tail is ungrounded anchor node
                    head_candidate = full_answer[now_head]
                    for now_try_time in range(10):
                        if len(head_candidate) > 1:
                            to_delete_head = random.sample(head_candidate, 1)[0]
                            guess_predicate = random.sample(data_kg.node2or[to_delete_head].keys(), 1)[0]
                            guess_tail = random.sample(data_kg.hr2t[(to_delete_head, guess_predicate)], 1)[0]
                        else:
                            guess_tail = random.randint(0, data_kg.num_entities - 1)
                            guess_predicate = random.sample(data_kg.node2ir[guess_tail].keys(), 1)[0]
                        if len(head_candidate - data_kg.tr2h[(guess_tail, guess_predicate)]) > 0:
                            grounded_dict[now_tail] = guess_tail
                            grounded_dict[now_predicate] = guess_predicate
                            grounded_neg_pred[now_predicate] = True
                            node2index[now_tail] = len(node2index)
                            break
                    else:
                        guess_tail = random.randint(0, data_kg.num_entities - 1)
                        guess_predicate = random.sample(data_kg.node2ir[guess_tail].keys(), 1)[0]
                        grounded_dict[now_tail] = guess_tail
                        grounded_dict[now_predicate] = guess_predicate
                        node2index[now_tail] = len(node2index)
                else:
                    tail_candidate = full_answer[now_tail]
                    for now_try_time in range(10):
                        if len(tail_candidate) > 1:
                            to_delete_tail = random.sample(tail_candidate, 1)[0]
                            guess_predicate = random.sample(data_kg.node2ir[to_delete_tail].keys(), 1)[0]
                            guess_head = random.sample(data_kg.tr2h[(to_delete_tail, guess_predicate)], 1)[0]
                        else:
                            guess_head = random.randint(0, data_kg.num_entities - 1)
                            guess_predicate = random.sample(data_kg.node2or[guess_head].keys(), 1)[0]
                        if len(tail_candidate - data_kg.hr2t[(guess_head, guess_predicate)]) > 0:
                            grounded_dict[now_head] = guess_head
                            grounded_dict[now_predicate] = guess_predicate
                            grounded_neg_pred[now_predicate] = True
                            node2index[now_tail] = len(node2index)
                            break
                    else:
                        guess_head = random.randint(0, data_kg.num_entities - 1)
                        guess_predicate = random.sample(data_kg.node2or[guess_head].keys(), 1)[0]
                        grounded_dict[now_head] = guess_head
                        grounded_dict[now_predicate] = guess_predicate
                        node2index[now_tail] = len(node2index)
            else:
                assert False, "There should not be an existential node that only connected to negation edge"
        if strict_meaningful_negation and sub_graph_negation_edge and False in grounded_neg_pred.values():
            return None, None, None
        if answer_has_changed:
            return grounded_dict, None, full_answer
        else:
            return grounded_dict, final_answer_tuple, full_answer

    def sample_other_query(self, data_kg: KnowledgeGraph, existing_grounded_dict):
        """
        Since the answer is assured by the sample_query, this is sampled basically randomly.
        """
        for pred_name in self.predicate_dict:
            if pred_name not in existing_grounded_dict:
                pred = self.predicate_dict[pred_name]
                if pred.head.name in existing_grounded_dict:
                    head_constraint = set(data_kg.node2or[existing_grounded_dict[pred.head.name]].keys())
                else:
                    head_constraint = set(range(data_kg.num_relations))
                if pred.tail.name in existing_grounded_dict:
                    tail_constraint = set(data_kg.node2ir[existing_grounded_dict[pred.tail.name]].keys())
                else:
                    tail_constraint = set(range(data_kg.num_relations))
                pred_candidate = head_constraint.intersection(tail_constraint)
                grounded_pred = random.sample(pred_candidate, 1)[0]
                existing_grounded_dict[pred_name] = grounded_pred
        for node_name in self.term_dict:
            if 's' in node_name and node_name not in existing_grounded_dict:
                consider_edges = self.term_name2predicate_name_dict[node_name]
                node_constraint_list = []
                for edge in consider_edges:
                    if node_name == self.predicate_dict[edge].head.name:
                        new_constraint = data_kg.r2h[existing_grounded_dict[edge]]
                    else:
                        new_constraint = data_kg.r2t[existing_grounded_dict[edge]]
                    node_constraint_list.append(new_constraint)
                node_constraint = set.intersection(*node_constraint_list)
                node_candidate = random.sample(node_constraint, 1)[0]
                existing_grounded_dict[node_name] = node_candidate
        return existing_grounded_dict

    def construct_now_candidate_set(self, index, kg_graph: KnowledgeGraph):
        now_term_candidate = defaultdict(set)
        free_variable_list = []
        for term_name in self.term_dict:
            if self.has_term_grounded_entity_id_list(term_name) and \
                    len(self.term_grounded_entity_id_dict[term_name]) > index:
                now_term_candidate[term_name] = {self.term_grounded_entity_id_dict[term_name][index]}
            else:
                now_term_candidate[term_name] = set(range(kg_graph.num_entities))
            if 'f' in term_name:
                free_variable_list.append(term_name)
        free_variable_list.sort()
        return now_term_candidate, free_variable_list

    def construct_query_graph(self, index, skip_predicate: List = None) -> \
            [KnowledgeGraph, KnowledgeGraph]:
        """
        Construct the query graph, for simplicity, it is split into two graphs, positive one and negative one.
        """
        sub_graph_edge, sub_graph_negation_edge = [], []
        skip_predicate = [] if not skip_predicate else skip_predicate
        for pred in self.predicate_dict.values():
            if pred.name not in skip_predicate:
                pred_triples = (pred.head.name, self.pred_grounded_relation_id_dict[pred.name][index], pred.tail.name)
                if pred.negated:
                    sub_graph_negation_edge.append(pred_triples)
                else:
                    sub_graph_edge.append(pred_triples)
        sub_kg_index = KGIndex()
        sub_kg_index.map_entity_name_to_id = {term: 0 for term in self.term_dict}
        sub_kg_index.map_relation_name_to_id = {predicate: 0 for predicate in self.predicate_dict}
        sub_kg = KnowledgeGraph(sub_graph_edge, sub_kg_index)
        neg_kg = KnowledgeGraph(sub_graph_negation_edge, sub_kg_index)
        return sub_kg, neg_kg

    def deterministic_query_set(self, index, kg_graph: KnowledgeGraph, skip_predicate: List = None,
                                return_full_match: bool = False):
        """
        The skip predicate is used in grounding the predicate, it can avoid creating new instance of Formula.
        The return full match is used in query sampling, if it is set to True, we use solve_EFO1 as the CSP problem.
        """
        now_term_candidate, free_variable_list = self.construct_now_candidate_set(index, kg_graph)
        sub_kg, neg_kg = self.construct_query_graph(index, skip_predicate)
        if len(free_variable_list) == 1 or return_full_match:
            answer_dict, exist_answer = csp_efo1(sub_kg, neg_kg, now_term_candidate, kg_graph)
            if return_full_match:
                to_return_dict = answer_dict if exist_answer else defaultdict(set)
                return to_return_dict
            else:  # We know the free variable has only one element.
                tuple_answer_set = set()
                if exist_answer:
                    for ans in answer_dict[free_variable_list[0]]:
                        tuple_answer_set.add((ans,))
                return tuple_answer_set
        else:
            answer_dict_list, exist_answer = csp_efox(sub_kg, neg_kg, now_term_candidate, kg_graph, free_variable_list)
            tuple_answer_set = set()
            if exist_answer:
                for ans in answer_dict_list:
                    new_ans = []
                    for free_variable in free_variable_list:
                        new_ans.append(ans[free_variable])
                    tuple_answer_set.add(tuple(new_ans))
            return tuple_answer_set

    def deterministic_query_set_with_initialization(self, index, kg_graph: KnowledgeGraph, skip_predicate: List = None,
                                return_full_match: bool = False, initialization: Dict = None):
        """
        Initialization is used to speed up the query sampling process.
        """
        now_term_candidate, free_variable_list = self.construct_now_candidate_set(index, kg_graph)
        if initialization:
            for term_name in initialization:
                now_term_candidate[term_name] = initialization[term_name].intersection(now_term_candidate[term_name])
        sub_kg, neg_kg = self.construct_query_graph(index, skip_predicate)
        if len(free_variable_list) == 1 or return_full_match:
            answer_dict, exist_answer = csp_efo1(sub_kg, neg_kg, now_term_candidate, kg_graph)
            if return_full_match:
                to_return_dict = answer_dict if exist_answer else defaultdict(set)
                return to_return_dict
            else:  # We know the free variable has only one element.
                tuple_answer_set = set()
                if exist_answer:
                    for ans in answer_dict[free_variable_list[0]]:
                        tuple_answer_set.add((ans,))
                return tuple_answer_set
        else:
            answer_dict_list, exist_answer = csp_efox(sub_kg, neg_kg, now_term_candidate, kg_graph, free_variable_list)
            tuple_answer_set = set()
            if exist_answer:
                for ans in answer_dict_list:
                    new_ans = []
                    for free_variable in free_variable_list:
                        new_ans.append(ans[free_variable])
                    tuple_answer_set.add(tuple(new_ans))
            return tuple_answer_set

    def deterministic_query_vec(self, index, relation_matrix_list: List, device, skip_predicate: List = None,
                                return_full_match: bool = False):
        """
        Detetministic Query using vector, the same as FIT algorithm
        """
        n_entity = relation_matrix_list[0].shape[0]
        all_candidates = {}
        for term_name in self.term_dict:
            if self.has_term_grounded_entity_id_list(term_name):
                all_candidates[term_name] = torch.zeros(n_entity).to(device)
                all_candidates[term_name][self.term_grounded_entity_id_dict[term_name][index]] = 1
            else:
                all_candidates[term_name] = torch.ones(n_entity).to(device)
        sub_graph_edge, sub_graph_negation_edge = [], []
        for pred in self.predicate_dict.values():
            pred_triples = (pred.head.name, self.pred_grounded_relation_id_dict[pred.name][index],
                            pred.tail.name)
            if pred.negated:
                sub_graph_negation_edge.append(pred_triples)
            else:
                sub_graph_edge.append(pred_triples)
        sub_kg_index = KGIndex()
        sub_kg_index.map_entity_name_to_id = {term: 0 for term in self.term_dict}
        sub_kg = KnowledgeGraph(sub_graph_edge, sub_kg_index)
        neg_kg = KnowledgeGraph(sub_graph_negation_edge, sub_kg_index)
        sub_kg_index.map_relation_name_to_id = {predicate: 0 for predicate in self.predicate_dict}
        vec_ans = solve_conjunctive(sub_kg, neg_kg, relation_matrix_list,
                                    all_candidates, 'Godel', 'Godel', 'f', device, 1)
        set_ans = {(ans,) for ans in range(len(vec_ans)) if vec_ans[ans] == 1}
        return set_ans

    def deterministic_query_brutal_set(self, index, kg_graph: KnowledgeGraph, skip_predicate: List = None):
        """
        Brutal solve EFOX, by solving EFO1 many times.
        """
        now_term_candidate, free_variable_list = self.construct_now_candidate_set(index, kg_graph)
        sub_kg, neg_kg = self.construct_query_graph(index, skip_predicate)
        candidate_answer_dict, exist_answer = csp_efo1(sub_kg, neg_kg, now_term_candidate, kg_graph)

        def candidate_dict_to_ans(candidate_dict, sub_kg: KnowledgeGraph, neg_kg: KnowledgeGraph, free_variable_list):
            if len(free_variable_list) == 1:
                ans_list = candidate_set_to_ans(candidate_dict)
                return ans_list
            new_free_variable = copy.deepcopy(free_variable_list)
            new_free_variable.sort(key=lambda x: len(candidate_dict[x]))
            enumerate_node = new_free_variable.pop(0)
            new_ans_list = []
            for enumerate_candidate in candidate_dict[enumerate_node]:
                new_candidate_dict = copy.deepcopy(candidate_dict)
                new_candidate_dict[enumerate_node] = {enumerate_candidate}
                sub_ans_dict, sub_exist_ans = csp_efo1(sub_kg, neg_kg, new_candidate_dict, kg_graph)
                sub_ans_list = candidate_dict_to_ans(sub_ans_dict, sub_kg, neg_kg, new_free_variable)
                for sub_ans in sub_ans_list:
                    new_ans_list.append(sub_ans)
            return new_ans_list

        if exist_answer:
            answer_dict_list = candidate_dict_to_ans(candidate_answer_dict, sub_kg, neg_kg, free_variable_list)
            answer_set = set()
            for ans in answer_dict_list:
                new_ans = []
                for free_variable in free_variable_list:
                    new_ans.append(ans[free_variable])
                answer_set.add(tuple(new_ans))
            return answer_set
        else:
            return {}

    def deterministic_query_solver(self, index, kg_graph: KnowledgeGraph, skip_predicate: List = None):
        """
        Solve the query by CSP solver.
        """
        problem = Problem()
        now_term_candidate, free_variable_list = self.construct_now_candidate_set(index, kg_graph)
        sub_kg, neg_kg = self.construct_query_graph(index, skip_predicate)
        for term_name in now_term_candidate:
            problem.addVariable(term_name, list(now_term_candidate[term_name]))
        positive_rels = [rel for (head, rel, tail) in sub_kg.triples]
        neg_rels = [rel for (head, rel, tail) in neg_kg.triples]
        for i, pos_edge in enumerate(sub_kg.triples):
            head, rel_name, tail = pos_edge
            if i == 0:
                problem.addConstraint(lambda x, y: (x, y) in kg_graph.r2ht[positive_rels[0]], (head, tail))
            elif i == 1:
                problem.addConstraint(lambda x, y: (x, y) in kg_graph.r2ht[positive_rels[1]], (head, tail))
            elif i == 2:
                problem.addConstraint(lambda x, y: (x, y) in kg_graph.r2ht[positive_rels[2]], (head, tail))
            elif i == 3:
                problem.addConstraint(lambda x, y: (x, y) in kg_graph.r2ht[positive_rels[3]], (head, tail))
            elif i == 4:
                problem.addConstraint(lambda x, y: (x, y) in kg_graph.r2ht[positive_rels[4]], (head, tail))
            elif i == 5:
                problem.addConstraint(lambda x, y: (x, y) in kg_graph.r2ht[positive_rels[5]], (head, tail))
            elif i == 6:
                problem.addConstraint(lambda x, y: (x, y) in kg_graph.r2ht[positive_rels[6]], (head, tail))
        for i, neg_edge in enumerate(neg_kg.triples):
            head, rel_name, tail = neg_edge
            if i == 0:
                problem.addConstraint(lambda x, y: (x, y) not in kg_graph.r2ht[neg_rels[0]], (head, tail))
            elif i == 1:
                problem.addConstraint(lambda x, y: (x, y) not in kg_graph.r2ht[neg_rels[1]], (head, tail))
            elif i == 2:
                problem.addConstraint(lambda x, y: (x, y) not in kg_graph.r2ht[neg_rels[2]], (head, tail))
        whole_answer = problem.getSolutions()
        free_answer_set = set()
        for answer in whole_answer:
            free_answer_set.add(tuple([answer[free_variable] for free_variable in free_variable_list]))
        return free_answer_set

    def deterministic_query(self, index, kg_graph, use_method: str = 'set'):
        """
        Return the answer of an EFO1/EFOX query
        """
        if use_method == 'set':
            answer_set = self.deterministic_query_set(index, kg_graph)
        elif use_method == 'brutal_set':
            answer_set = self.deterministic_query_brutal_set(index, kg_graph)
        elif use_method == 'solver':
            answer_set = self.deterministic_query_solver(index, kg_graph)
        else:
            raise NotImplementedError
        return answer_set

    def get_query_graph(self):
        """
        Return the query graph, which consists of a dict representing entities, and adj matrix representing connections.
        """
        entity_dict = {}
        adj_matrix = np.zeros((len(self.term_dict), len(self.term_dict)))
        e_num, f_num = len(self.existential_variable_dict), len(self.free_variable_dict)
        c_num = len(self.term_dict) - e_num - f_num

        for i in range(c_num):
            entity_dict[i] = 's' + str(i + 1)
        for j in range(e_num):
            entity_dict[j] = 'e' + str(j + 1 + c_num)
        for k in range(f_num):
            entity_dict[k] = 'f' + str(k + 1 + c_num + e_num)
        for i, pred in enumerate(self.predicate_dict):
            head_name, pred_name, tail_name = pred.head_name, pred.pred_name, pred.tail_name
        return entity_dict, adj_matrix


    @property
    def free_variable_dict(self):
        return OrderedDict({k: v
                            for k, v in self.term_dict.items()
                            if v.state == Term.FREE})

    @property
    def universal_variable_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.UNIVERSAL}

    @property
    def existential_variable_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.EXISTENTIAL}

    @property
    def symbol_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.SYMBOL}

    @property
    def is_sentence(self):
        """
        Determine the state of the formula
        A formula is sentence when all variables are quantified
        """
        return len({k: v for k, v in self.term_dict.items()
                    if v.state == Term.FREE}) == 0

    @property
    def lstr(self):
        return self.formula.lstr()

    @property
    def num_instances(self):
        num_instances = len(self.easy_answer_list)
        assert num_instances == len(self.hard_answer_list)
        for k in self.symbol_dict:
            assert num_instances == len(
                self.get_term_grounded_entity_id_list(k))

        for k in self.predicate_dict:
            assert num_instances == len(
                self.get_pred_grounded_relation_id_list(k))

        return len(self.easy_answer_list)

    @property
    def num_predicates(self):
        return self.formula.num_predicates

    @property
    def quantifier_rank(self):
        return len(self.existential_variable_dict) \
            + len(self.universal_variable_dict) \
            + len(self.free_variable_dict)

    def get_all_grounded_ids(self):
        entity_ids = []
        for term_name in self.term_grounded_entity_id_dict:
            entity_ids += self.term_grounded_entity_id_dict[term_name]
        relation_ids = []
        for pred_name in self.pred_grounded_relation_id_dict:
            relation_ids += self.pred_grounded_relation_id_dict[pred_name]
        return entity_ids, relation_ids


class DisjunctiveFormula:
    """
    We suppose the DNF formula is here, thus, no GNN computation is needed, all we need is gather the answer in each
    subformula.
    """

    def __init__(self,
                 formula_list: List[ConjunctiveFormula]) -> None:
        self.formula_list: List[ConjunctiveFormula] = formula_list
        self.easy_answer_list = []
        self.hard_answer_list = []
        self.noisy_answer_list = []
        self.grounding_dict_list = []

        # update internal storage
        self.predicate_dict: Dict[str, Atomic] = {}
        self.pred_grounded_relation_id_dict: Dict[str, List] = {}

        self.term_dict: Dict[str, Term] = {}
        self.free_term_dict: Dict[str, Term] = {}
        self.term_grounded_entity_id_dict: Dict[str, List] = {}

        self.term_name2predicate_name_dict: Dict[str, str] = defaultdict(list)
        # run initialization
        self._init_query()

    def _init_query(self):
        easy_ans_set, hard_ans_set, noisy_ans_set = set(), set(), set()
        for formula in self.formula_list:
            easy_ans_set.update(set(formula.easy_answer_list))
            hard_ans_set.update(set(formula.hard_answer_list))
            noisy_ans_set.update(set(formula.noisy_answer_list))
        self.easy_answer_list, self.hard_answer_list, self.noisy_answer_list = list(easy_ans_set), list(hard_ans_set), \
            list(noisy_ans_set)

        self.predicate_dict = {}
        for sub_formula in self.formula_list:
            self.predicate_dict.update(sub_formula.formula.get_atomics())
        self.pred_grounded_relation_id_dict = {
            name: predicate.relation_id_list
            for name, predicate in self.predicate_dict.items()
        }

        self.term_dict = {}
        for _, pred in self.predicate_dict.items():
            for t in pred.get_terms():
                self.term_dict[t.name] = t
                if 'f' in t.name:
                    self.free_term_dict[t.name] = t

        self.term_grounded_entity_id_dict = {name: term.entity_id_list
                                             for name, term in self.term_dict.items()}

        for pred_name, predicate in self.predicate_dict.items():
            head, tail = predicate.get_terms()
            self.term_name2predicate_name_dict[head.name].append(pred_name)
            self.term_name2predicate_name_dict[tail.name].append(pred_name)

    def append_relation_and_symbols(self, append_dict):
        for sub_formula in self.formula_list:
            sub_append_dict = {key: append_dict[key] for key in append_dict if key in sub_formula.term_dict or
                               key in sub_formula.predicate_dict}
            sub_formula.append_relation_and_symbols(sub_append_dict)

    def append_qa_instances(self,
                            append_dict,
                            easy_answers=[],
                            hard_answers=[],
                            noisy_answer=[]):
        self.append_relation_and_symbols(append_dict)
        self.easy_answer_list.append(easy_answers)
        self.hard_answer_list.append(hard_answers)
        self.noisy_answer_list.append(noisy_answer)

    def sample_query(self, kg: KnowledgeGraph, strict_meaningful_negation: bool, kg_matrix=None, max_ans: int = None):
        selected_sub_formula_index = random.randint(0, len(self.formula_list) - 1)
        selected_sub_formula = self.formula_list[selected_sub_formula_index]
        grounded_dict, sub_answer, epfo_constraint = selected_sub_formula.sample_query(
            kg, strict_meaningful_negation, kg_matrix, max_ans)
        if not grounded_dict:
            return None, None, None
        for index in range(len(self.formula_list)):
            if index != selected_sub_formula_index:
                grounded_dict = self.formula_list[index].sample_other_query(kg, grounded_dict)
        if len(self.formula_list) == 1:
            return grounded_dict, sub_answer, epfo_constraint
        else:
            return grounded_dict, None, epfo_constraint

    def deterministic_query(self, index, kg: Union[KnowledgeGraph, List], method: str = 'set', device='cpu'):
        if method == 'vec':
            vec_ans = solve_EFO1(self, kg, 'Godel', 'Godel', index, device, 1)
            set_ans = {(ans,) for ans in range(len(vec_ans)) if vec_ans[ans] == 1}
            return set_ans
        all_answer = set()
        for sub_formula in self.formula_list:
            sub_answer = sub_formula.deterministic_query(index, kg, method)
            all_answer.update(sub_answer)
        return all_answer

    @property
    def lstr(self):
        if len(self.formula_list) == 1:
            lstr = self.formula_list[0].lstr
        else:
            lstr = "|".join(f"({f.lstr})" for f in self.formula_list)
        return lstr


class EFO1Query:
    """
    The first order formula

    self.formula is parsed from the formula and provide the operator tree for
        evaluation
    self.atomic_dict stores each predicates by its name, which are edges
    self.term_dict stores each symbol by its name

    self.pred_grounded_relation_id_dict stores the relation id for each predicate
    self.term_grounded_entity_id_dict stores the entity id for each symbol (term)


    self.easy_answer_list list for easy answers
    self.hard_answer_list list for hard answers
    self.noisy_answer_list list for noisy answers

    each answer is a dict whose keys are the variable and values are the list of possible answers
    """

    def __init__(self,
                 formula: Formula) -> None:
        self.formula: Formula = formula
        self.easy_answer_list = []
        self.hard_answer_list = []
        self.noisy_answer_list = []
        self.grounding_dict_list = []

        # update internal storage
        self.atomic_dict: Dict[str, Atomic] = {}
        self.pred_grounded_relation_id_dict: Dict[str, List] = {}

        self.term_dict: Dict[str, Term] = {}
        self.term_grounded_entity_id_dict: Dict[str, List] = {}

        self.term_name2atomic_name_list: Dict[str, str] = defaultdict(list)
        # run initialization
        self._init_query()

    def _init_query(self):
        # handle predicates and relations
        self.atomic_dict = self.formula.get_atomics()
        self.pred_grounded_relation_id_dict = {}
        for alstr, atomic in self.atomic_dict.items():
            rel_name = atomic.relation
            self.pred_grounded_relation_id_dict[rel_name] = []

        # handle terms
        self.term_dict = {}
        for alstr, atomic in self.atomic_dict.items():
            for t in atomic.get_terms():
                self.term_dict[t.name] = t
        for name, term in self.term_dict.items():
            self.term_grounded_entity_id_dict[name] = []

        for alstr, atomic in self.atomic_dict.items():
            head, tail = atomic.get_terms()
            self.term_name2atomic_name_list[head.name].append(alstr)
            self.term_name2atomic_name_list[tail.name].append(alstr)


    def append_relation_and_symbols(self, append_dict):
        for k, v in append_dict.items():
            if k in self.term_dict:
                self.term_grounded_entity_id_dict[k].append(v)
            else:
                self.pred_grounded_relation_id_dict[k].append(v)

    def append_qa_instances(self,
                            append_dict,
                            easy_answers=[],
                            hard_answers=[],
                            noisy_answer=[]):
        self.append_relation_and_symbols(append_dict)
        self.easy_answer_list.append(easy_answers)
        self.hard_answer_list.append(hard_answers)
        self.noisy_answer_list.append(noisy_answer)

    def has_term_grounded_entity_id_list(self, key):
        return len(self.term_grounded_entity_id_dict[key]) > 0

    def get_term_grounded_entity_id_list(self, key):
        return self.term_grounded_entity_id_dict[key]

    def has_pred_grounded_relation_id_list(self, key):
        return len(self.pred_grounded_relation_id_dict[key]) > 0

    def get_pred_grounded_relation_id_list(self, key):
        return self.pred_grounded_relation_id_dict[key]

    @property
    def free_variable_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.FREE}

    @property
    def universal_variable_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.UNIVERSAL}

    @property
    def existential_variable_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.EXISTENTIAL}

    @property
    def symbol_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.SYMBOL}

    @property
    def is_sentence(self):
        """
        Determine the state of the formula
        A formula is sentence when all variables are quantified
        """
        return len({k: v for k, v in self.term_dict.items()
                    if v.state == Term.FREE}) == 0

    @property
    def lstr(self):
        return self.formula.lstr

    @property
    def num_instances(self):
        num_instances = len(self.easy_answer_list)
        assert num_instances == len(self.hard_answer_list)
        for k in self.symbol_dict:
            assert num_instances == len(
                self.get_term_grounded_entity_id_list(k))

        for k in self.atomic_dict:
            pred_name = self.atomic_dict[k].relation
            assert num_instances == len(
                self.get_pred_grounded_relation_id_list(pred_name))

        return len(self.easy_answer_list)

    @property
    def num_predicates(self):
        return self.formula.num_atomics

    @property
    def quantifier_rank(self):
        return len(self.existential_variable_dict) \
               + len(self.universal_variable_dict) \
               + len(self.free_variable_dict)

    def get_all_gounded_ids(self):
        entity_ids = []
        for term_name in self.term_grounded_entity_id_dict:
            entity_ids += self.term_grounded_entity_id_dict[term_name]
        relation_ids = []
        for pred_name in self.pred_grounded_relation_id_dict:
            relation_ids += self.pred_grounded_relation_id_dict[pred_name]
        return entity_ids, relation_ids

    def get_bfs_variable_ordering(self, source_var_name='f'):
        """
        get variable ordering by a topological sort
        """
        visited_vars = set(source_var_name)
        var_name_levels = [[(source_var_name, 0)]]
        while True:
            for var_name, order in var_name_levels[-1]:
                next_var_name_level = []
                for atomic_name in self.term_name2atomic_name_list[var_name]:
                    atomic = self.atomic_dict[atomic_name]
                    for term in atomic.get_terms():
                        if term.state == Term.SYMBOL:
                            continue

                        if term.name not in visited_vars:
                            visited_vars.add(term.name)
                        else:
                            continue

                        next_var_name_level.append((term.name, order + 1))

            if len(next_var_name_level) == 0:
                break
            else:
                var_name_levels.append(next_var_name_level)

        return var_name_levels